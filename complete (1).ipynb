{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpvcG5_GXzyr",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install yfinance transformers accelerate datasets peft matplotlib seaborn torch psutil\n",
        "!pip install -U peft"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import psutil\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "metadata": {
        "id": "qtzH9ogOZpwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check System Resources\n",
        "def check_resources():\n",
        "    ram = psutil.virtual_memory().available / (1024**3)  # GB\n",
        "    disk = psutil.disk_usage('/').free / (1024**3)  # GB\n",
        "    print(f\"Available RAM: {ram:.2f} GB, Available Disk: {disk:.2f} GB\")\n",
        "    if ram < 2 or disk < 10:\n",
        "        raise RuntimeError(\"Insufficient resources for this operation.\")\n",
        "check_resources()"
      ],
      "metadata": {
        "id": "9FZQlAwMZpyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Configuration\n",
        "BASE_MODEL = \"EleutherAI/gpt-neo-1.3B\"  # Base model without PEFT\n",
        "REPORT_COLUMNS = [\n",
        "    \"Ticker\", \"Sector\", \"52-Week High\", \"52-Week Low\",\n",
        "    \"Current Price\", \"Market Cap\", \"PE\", \"PB\", \"PEG\", \"ROC\", \"ROCE\", \"PH\"\n",
        "]"
      ],
      "metadata": {
        "id": "aO41M315Zp1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Base Model\n",
        "def load_base_model(base_model_name):\n",
        "    print(\"Loading base model (optimized for CPU)...\")\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(base_model_name, device_map=\"cpu\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "    return base_model, tokenizer\n",
        "\n",
        "base_model, tokenizer = load_base_model(BASE_MODEL)"
      ],
      "metadata": {
        "id": "BV4wb6PbZp5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch NIFTY 100 Stock Data\n",
        "def fetch_nifty_100():\n",
        "    print(\"Fetching NIFTY 100 data...\")\n",
        "    nifty_100_tickers = [\"RELIANCE.NS\", \"TCS.NS\", \"HDFCBANK.NS\", \"INFY.NS\", \"HINDUNILVR.NS\", \"ICICIBANK.NS\", \"KOTAKBANK.NS\", \"SBIN.NS\",\n",
        "                         \"BHARTIARTL.NS\", \"ITC.NS\", \"AXISBANK.NS\", \"BAJFINANCE.NS\", \"HCLTECH.NS\", \"MARUTI.NS\", \"SUNPHARMA.NS\", \"ADANIGREEN.NS\",\n",
        "                         \"ADANIPORTS.NS\", \"ADANITRANS.NS\", \"AMBUJACEM.NS\", \"APOLLOHOSP.NS\", \"ASIANPAINT.NS\", \"AUROPHARMA.NS\", \"BAJAJ-AUTO.NS\",\n",
        "                         \"BAJAJFINSV.NS\", \"BANDHANBNK.NS\", \"BANKBARODA.NS\", \"BEL.NS\", \"BERGEPAINT.NS\", \"BPCL.NS\", \"BRITANNIA.NS\", \"CIPLA.NS\",\n",
        "                         \"COALINDIA.NS\", \"DABUR.NS\", \"DIVISLAB.NS\", \"DLF.NS\", \"DRREDDY.NS\", \"EICHERMOT.NS\", \"GAIL.NS\", \"GLAND.NS\", \"GODREJCP.NS\",\n",
        "                         \"GRASIM.NS\", \"HAVELLS.NS\", \"HEROMOTOCO.NS\", \"HINDALCO.NS\", \"HINDPETRO.NS\", \"ICICIPRULI.NS\", \"INDIGO.NS\", \"INDUSINDBK.NS\",\n",
        "                         \"IOC.NS\", \"IRCTC.NS\", \"JSWSTEEL.NS\", \"JUBLFOOD.NS\", \"L&TFH.NS\", \"LALPATHLAB.NS\", \"LICI.NS\", \"LT.NS\", \"LUPIN.NS\",\n",
        "                         \"M&M.NS\", \"MCDOWELL-N.NS\", \"MINDTREE.NS\", \"MOTHERSUMI.NS\", \"NAUKRI.NS\", \"NMDC.NS\", \"NTPC.NS\", \"ONGC.NS\", \"PAGEIND.NS\",\n",
        "                         \"PEL.NS\", \"PETRONET.NS\", \"PIIND.NS\", \"PNB.NS\", \"POWERGRID.NS\", \"PVR.NS\", \"RAMCOCEM.NS\", \"SBILIFE.NS\", \"SHREECEM.NS\",\n",
        "                         \"SIEMENS.NS\", \"SRF.NS\", \"SRTRANSFIN.NS\", \"TATACHEM.NS\", \"TATACONSUM.NS\", \"TATAMOTORS.NS\", \"TATAPOWER.NS\", \"TATASTEEL.NS\",\n",
        "                         \"TECHM.NS\", \"TITAN.NS\", \"TORNTPHARM.NS\", \"TORNTPOWER.NS\", \"TVSMOTOR.NS\", \"UBL.NS\", \"ULTRACEMCO.NS\", \"UPL.NS\", \"VEDL.NS\",\n",
        "                         \"VOLTAS.NS\", \"WIPRO.NS\", \"ZEEL.NS\", \"ZYDUSLIFE.NS\"]\n",
        "\n",
        "    try:\n",
        "        stocks_data = yf.download(nifty_100_tickers, period=\"1y\", progress=False)\n",
        "        return stocks_data\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching stock data: {e}\")\n",
        "        return pd.DataFrame()\n",
        "stocks_data = fetch_nifty_100()"
      ],
      "metadata": {
        "id": "STjNICVYZp8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_stock_data(stocks_data, sector_mapping):\n",
        "    print(\"Processing stock data...\")\n",
        "    stocks_summary = []\n",
        "\n",
        "    if stocks_data.empty:\n",
        "        print(\"No stock data available. Exiting processing.\")\n",
        "        return pd.DataFrame()  # Return empty DataFrame if no data\n",
        "\n",
        "    for ticker in stocks_data.columns.levels[1]:\n",
        "        try:\n",
        "            ticker_data = stocks_data[\"Adj Close\", ticker].dropna()\n",
        "            if ticker_data.empty:\n",
        "                print(f\"No adjusted close data for {ticker}. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            high = ticker_data.max()\n",
        "            low = ticker_data.min()\n",
        "            current_price = ticker_data.iloc[-1]\n",
        "\n",
        "            # Mock additional parameters\n",
        "            date = ticker_data.index[-1]\n",
        "            volume = stocks_data[\"Volume\", ticker].iloc[-1] if \"Volume\" in stocks_data.columns.levels[0] else None\n",
        "            sector = sector_mapping.get(ticker.split('.')[0], \"Unknown\")\n",
        "            market_cap = 1_000_000  # Placeholder\n",
        "            pe, pb, peg, roc, roce, ph = 15, 1.5, 1.2, 25, 30, 70  # Example placeholders\n",
        "\n",
        "            stocks_summary.append({\n",
        "                \"Date\": date, \"Ticker\": ticker, \"Sector\": sector,\n",
        "                \"52-Week High\": high, \"52-Week Low\": low, \"Current Price\": current_price,\n",
        "                \"Volume\": volume, \"Market Cap\": market_cap, \"PE\": pe, \"PB\": pb,\n",
        "                \"PEG\": peg, \"ROC\": roc, \"ROCE\": roce, \"PH\": ph\n",
        "            })\n",
        "        except IndexError:\n",
        "            print(f\"IndexError for {ticker}. Skipping.\")\n",
        "        except KeyError:\n",
        "            print(f\"KeyError for {ticker}. Skipping.\")\n",
        "\n",
        "    return pd.DataFrame(stocks_summary)"
      ],
      "metadata": {
        "id": "weCfL2dVZp-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sector_mapping = {     \"RELIANCE\": \"Energy\",     \"TCS\": \"IT\",     \"HDFCBANK\": \"Financials\",\n",
        "                  \"INFY\": \"IT\",     \"HINDUNILVR\": \"Consumer Goods\",     \"ICICIBANK\": \"Financials\",\n",
        "                       \"KOTAKBANK\": \"Financials\",     \"SBIN\": \"Financials\",     \"BHARTIARTL\": \"Telecom\",\n",
        "                       \"ITC\": \"Consumer Goods\",     \"AXISBANK\": \"Financials\",     \"BAJFINANCE\": \"Financials\",\n",
        "                       \"HCLTECH\": \"IT\",     \"MARUTI\": \"Automobile\",     \"SUNPHARMA\": \"Healthcare\",     \"ADANIGREEN\": \"Energy\",\n",
        "                       \"ADANIPORTS\": \"Transportation\",     \"ADANITRANS\": \"Utilities\",     \"AMBUJACEM\": \"Materials\",\n",
        "                       \"APOLLOHOSP\": \"Healthcare\",     \"ASIANPAINT\": \"Materials\",     \"AUROPHARMA\": \"Healthcare\",\n",
        "                       \"BAJAJ-AUTO\": \"Automobile\",     \"BAJAJFINSV\": \"Financials\",     \"BANDHANBNK\": \"Financials\",\n",
        "                       \"BANKBARODA\": \"Financials\",     \"BEL\": \"Industrials\",     \"BERGEPAINT\": \"Materials\",     \"BPCL\": \"Energy\",\n",
        "                       \"BRITANNIA\": \"Consumer Goods\",     \"CIPLA\": \"Healthcare\",     \"COALINDIA\": \"Energy\",\n",
        "                       \"DABUR\": \"Consumer Goods\",     \"DIVISLAB\": \"Healthcare\",     \"DLF\": \"Real Estate\",     \"DRREDDY\": \"Healthcare\",\n",
        "                       \"EICHERMOT\": \"Automobile\",     \"GAIL\": \"Energy\",     \"GLAND\": \"Healthcare\",     \"GODREJCP\": \"Consumer Goods\",\n",
        "                       \"GRASIM\": \"Materials\",     \"HAVELLS\": \"Consumer Goods\",     \"HEROMOTOCO\": \"Automobile\",     \"HINDALCO\": \"Materials\",\n",
        "                       \"HINDPETRO\": \"Energy\",     \"ICICIPRULI\": \"Financials\",     \"INDIGO\": \"Transportation\",     \"INDUSINDBK\": \"Financials\",\n",
        "                       \"IOC\": \"Energy\",     \"IRCTC\": \"Transportation\",     \"JSWSTEEL\": \"Materials\",     \"JUBLFOOD\": \"Consumer Goods\",\n",
        "                       \"L&TFH\": \"Financials\",     \"LALPATHLAB\": \"Healthcare\",     \"LICI\": \"Financials\",     \"LT\": \"Industrials\",\n",
        "                       \"LUPIN\": \"Healthcare\",     \"M&M\": \"Automobile\",     \"MCDOWELL-N\": \"Consumer Goods\",     \"MINDTREE\": \"IT\",\n",
        "                       \"MOTHERSUMI\": \"Automobile\",     \"NAUKRI\": \"IT\",     \"NMDC\": \"Materials\",     \"NTPC\": \"Utilities\",     \"ONGC\": \"Energy\",\n",
        "                       \"PAGEIND\": \"Consumer Goods\",     \"PEL\": \"Financials\",     \"PETRONET\": \"Energy\",     \"PIIND\": \"Materials\",\n",
        "                       \"PNB\": \"Financials\",     \"POWERGRID\": \"Utilities\",     \"PVR\": \"Consumer Services\",     \"RAMCOCEM\": \"Materials\",\n",
        "                       \"SBILIFE\": \"Financials\",     \"SHREECEM\": \"Materials\",     \"SIEMENS\": \"Industrials\",     \"SRF\": \"Materials\",\n",
        "                       \"SRTRANSFIN\": \"Financials\", \"TATACHEM\": \"Materials\", \"TATACONSUM\": \"Consumer Goods\", \"TATAMOTORS\": \"Automobile\",\n",
        "                       \"TATAPOWER\": \"Utilities\", \"TATASTEEL\": \"Materials\", \"TECHM\": \"IT\", \"TITAN\": \"Consumer Goods\", \"TORNTPHARM\": \"Healthcare\",\n",
        "                       \"TORNTPOWER\": \"Utilities\", \"TVSMOTOR\": \"Automobile\", \"UBL\": \"Consumer Goods\", \"ULTRACEMCO\": \"Materials\", \"UPL\": \"Materials\",\n",
        "                       \"VEDL\": \"Materials\", \"VOLTAS\": \"Consumer Goods\", \"WIPRO\": \"IT\", \"ZEEL\": \"Consumer Services\", \"ZYDUSLIFE\": \"Healthcare\" }\n",
        "stocks_summary = process_stock_data(stocks_data, sector_mapping)"
      ],
      "metadata": {
        "id": "viVSW_lSdoKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter Stocks Based on Criteria\n",
        "def filter_stocks(stocks_summary):\n",
        "    print(\"Filtering stocks based on optimization criteria...\")\n",
        "    filtered_stocks = stocks_summary[\n",
        "        (stocks_summary[\"PE\"] < 20) &\n",
        "        (stocks_summary[\"PB\"] < 2) &\n",
        "        (stocks_summary[\"PEG\"] < 2) &\n",
        "        (stocks_summary[\"ROC\"] > 20) &\n",
        "        (stocks_summary[\"ROCE\"] > 20) &\n",
        "        (stocks_summary[\"PH\"] > 60)\n",
        "    ]\n",
        "    return filtered_stocks\n",
        "\n",
        "filtered_stocks = filter_stocks(stocks_summary)\n"
      ],
      "metadata": {
        "id": "3Fj8OVobdoPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_recommendations(base_model, tokenizer, stock_data):\n",
        "    print(\"Generating recommendations...\")\n",
        "\n",
        "    # Create the pipeline without specifying a device\n",
        "    pipe = pipeline(\"text-generation\", model=base_model, tokenizer=tokenizer)\n",
        "\n",
        "    recommendations = []\n",
        "    for _, row in stock_data.iterrows():\n",
        "        prompt = (\n",
        "            f\"Provide investment advice for {row['Ticker']} in the {row['Sector']} sector. \"\n",
        "            f\"52-week high: {row['52-Week High']}, low: {row['52-Week Low']}, \"\n",
        "            f\"current price: {row['Current Price']}, PE: {row['PE']}, PB: {row['PB']}.\"\n",
        "        )\n",
        "        # Generate recommendations\n",
        "        result = pipe(prompt, max_length=100, num_return_sequences=1)\n",
        "        recommendations.append(result[0][\"generated_text\"])\n",
        "\n",
        "    # Add recommendations to the DataFrame\n",
        "    stock_data[\"Recommendations\"] = recommendations\n",
        "    return stock_data\n",
        "\n",
        "# Ensure 'filtered_stocks' is not empty before running\n",
        "if not filtered_stocks.empty:\n",
        "    recommendations = generate_recommendations(base_model, tokenizer, filtered_stocks)\n",
        "else:\n",
        "    print(\"No stocks available for recommendation.\")"
      ],
      "metadata": {
        "id": "5HRHTmP8gTxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Performance\n",
        "def visualize_performance(filtered_stocks):\n",
        "    print(\"Visualizing performance trends...\")\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.lineplot(data=filtered_stocks, x=\"Ticker\", y=\"Current Price\", hue=\"Sector\", marker=\"o\")\n",
        "    plt.title(\"Performance Trends of Selected Stocks\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "def visualize_top_10(filtered_stocks):\n",
        "    top_10 = filtered_stocks.nlargest(10, \"Current Price\")\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(data=top_10, x=\"Ticker\", y=\"Current Price\", hue=\"Sector\")\n",
        "    plt.title(\"Top 10 Stocks by Current Price\")\n",
        "    plt.show()\n",
        "\n",
        "def visualize_sector_distribution(filtered_stocks):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.countplot(data=filtered_stocks, x=\"Sector\", palette=\"cool\")\n",
        "    plt.title(\"Sector Distribution of Selected Stocks\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "# Final Visualization Calls\n",
        "if not filtered_stocks.empty:\n",
        "    visualize_performance(filtered_stocks)\n",
        "    visualize_top_10(filtered_stocks)\n",
        "    visualize_sector_distribution(filtered_stocks)\n",
        "    print(\"Final Recommendations:\")\n",
        "    print(recommendations[[\"Ticker\", \"Sector\", \"Recommendations\"]])\n",
        "else:\n",
        "    print(\"No data to visualize.\")"
      ],
      "metadata": {
        "id": "iVaxE7gnE2kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def predict_future_prices(filtered_stocks, stocks_data, days=30):\n",
        "    print(\"Predicting future prices for top 10 performing stocks...\")\n",
        "\n",
        "    top_10 = filtered_stocks.nlargest(10, \"Current Price\")\n",
        "    predictions = {}\n",
        "\n",
        "    for ticker in top_10[\"Ticker\"]:\n",
        "        try:\n",
        "            # Extract historical data for the ticker\n",
        "            ticker_data = stocks_data[\"Adj Close\", ticker].dropna()\n",
        "\n",
        "            # Create lagged features\n",
        "            df = pd.DataFrame({\"Price\": ticker_data.values})\n",
        "            for lag in range(1, 6):  # Create 5 lagged features\n",
        "                df[f\"Lag_{lag}\"] = df[\"Price\"].shift(lag)\n",
        "            df = df.dropna()  # Drop rows with missing values\n",
        "\n",
        "            # Prepare data for training\n",
        "            X = df.drop(columns=[\"Price\"]).values\n",
        "            y = df[\"Price\"].values\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "            # Train a RandomForestRegressor\n",
        "            model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Predict future prices\n",
        "            last_known_features = X[-1]  # Start with the most recent data\n",
        "            future_prices = []\n",
        "\n",
        "            for _ in range(days):\n",
        "                next_price = model.predict([last_known_features])[0]\n",
        "                future_prices.append(next_price)\n",
        "\n",
        "                # Update features for the next prediction\n",
        "                last_known_features = np.roll(last_known_features, -1)\n",
        "                last_known_features[-1] = next_price\n",
        "\n",
        "            predictions[ticker] = future_prices\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {ticker}: {e}\")\n",
        "            continue\n",
        "\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "7kBDHkDIQJlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_future_predictions(future_predictions, stocks_data, days=30):\n",
        "    print(\"Visualizing historical and predicted prices...\")\n",
        "\n",
        "    plt.figure(figsize=(14, 8))\n",
        "\n",
        "    for i, (ticker, future_prices) in enumerate(future_predictions.items()):\n",
        "        ticker_data = stocks_data[\"Adj Close\", ticker].dropna()\n",
        "        historical_prices = ticker_data.values\n",
        "\n",
        "        # Combine historical and predicted prices\n",
        "        time_historical = np.arange(len(historical_prices))\n",
        "        time_future = np.arange(len(historical_prices), len(historical_prices) + days)\n",
        "\n",
        "        plt.plot(time_historical, historical_prices, label=f\"{ticker} - Historical\")\n",
        "        plt.plot(time_future, future_prices, linestyle=\"--\", label=f\"{ticker} - Predicted\")\n",
        "\n",
        "    plt.title(\"Historical and Predicted Prices for Top 10 Performing Stocks\")\n",
        "    plt.xlabel(\"Days\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "nXrls6joeaMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization 2: Individual Stock Trends\n",
        "def visualize_individual_stocks(future_predictions, stocks_data, days=30):\n",
        "    print(\"Creating individual stock trend subplots...\")\n",
        "    num_stocks = len(future_predictions)\n",
        "    fig, axes = plt.subplots(num_stocks, 1, figsize=(10, 5 * num_stocks), sharex=True)\n",
        "\n",
        "    for ax, (ticker, future_prices) in zip(axes, future_predictions.items()):\n",
        "        ticker_data = stocks_data[\"Adj Close\", ticker].dropna()\n",
        "        historical_prices = ticker_data.values\n",
        "\n",
        "        # Combine historical and predicted prices\n",
        "        all_prices = np.concatenate([historical_prices, future_prices])\n",
        "        time = np.arange(len(all_prices))\n",
        "\n",
        "        ax.plot(time[:len(historical_prices)], historical_prices, label=\"Historical\", color=\"blue\")\n",
        "        ax.plot(time[len(historical_prices):], future_prices, linestyle=\"--\", label=\"Predicted\", color=\"orange\")\n",
        "        ax.set_title(f\"{ticker} - Historical vs. Predicted Prices\")\n",
        "        ax.set_ylabel(\"Price\")\n",
        "        ax.legend()\n",
        "\n",
        "    plt.xlabel(\"Days\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "RHWYcpfueaSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Calls to New Visualizations\n",
        "if not filtered_stocks.empty:\n",
        "    future_predictions = predict_future_prices(filtered_stocks, stocks_data)\n",
        "    visualize_future_predictions(future_predictions, stocks_data)\n",
        "    visualize_individual_stocks(future_predictions, stocks_data)\n",
        "else:\n",
        "    print(\"No data available for future price prediction.\")"
      ],
      "metadata": {
        "id": "ZnBbQ3kkevCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "O_IQ4iE4BXrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib"
      ],
      "metadata": {
        "id": "jtVeN1ZX-gju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MNVcmW4qBeLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the folder path in Google Drive\n",
        "google_drive_folder = \"/content/drive/MyDrive/Colab Notebooks/Stock_Recommendation\""
      ],
      "metadata": {
        "id": "ltM4bpaHBuci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "zrO9ESS4MfHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model_and_config(model, tokenizer, sector_mapping, folder_path=google_drive_folder, file_name=\"stock_recommend.pkl\"):\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "    print(f\"Saving model and configuration to {file_path}...\")\n",
        "\n",
        "    # Save the model and tokenizer\n",
        "    model_path = os.path.join(folder_path, \"model\")\n",
        "    model.save_pretrained(model_path)\n",
        "    print(f\"Base model saved to {model_path}\")\n",
        "\n",
        "    tokenizer_path = os.path.join(folder_path, \"tokenizer\")\n",
        "    tokenizer.save_pretrained(tokenizer_path)\n",
        "    print(f\"Tokenizer saved to {tokenizer_path}\")\n",
        "\n",
        "    # Save the sector mapping\n",
        "    joblib.dump({\n",
        "        \"sector_mapping\": sector_mapping\n",
        "    }, file_path)\n",
        "    print(f\"Sector mapping and additional configurations saved to {file_path}\")\n",
        "\n",
        "    print(\"Model and configuration saved successfully.\")\n",
        "\n",
        "    # Download the files\n",
        "    print(\"Downloading files...\")\n",
        "    files.download(file_path)\n",
        "    for filename in os.listdir(model_path):\n",
        "        files.download(os.path.join(model_path, filename))\n",
        "    for filename in os.listdir(tokenizer_path):\n",
        "        files.download(os.path.join(tokenizer_path, filename))\n",
        "    print(\"Files downloaded successfully.\")\n"
      ],
      "metadata": {
        "id": "s01dm1f3-ou6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_model_and_config(base_model, tokenizer, sector_mapping)"
      ],
      "metadata": {
        "id": "h-GUjphOCZxC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}